{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is System\n",
      " Volume Serial Number is 2CA8-E3EA\n",
      "\n",
      " Directory of C:\\Users\\amarthak\\Documents\\dg-spawn-chat-backend\\opt\\data\n",
      "\n",
      "24-01-2020  17:38    <DIR>          .\n",
      "24-01-2020  17:38    <DIR>          ..\n",
      "24-01-2020  17:38    <DIR>          .ipynb_checkpoints\n",
      "10-01-2020  10:00             6,967 spawn_en_data.json\n",
      "10-01-2020  10:00             9,378 spawn_hi_data.json\n",
      "24-01-2020  17:38                72 Untitled.ipynb\n",
      "               3 File(s)         16,417 bytes\n",
      "               3 Dir(s)  388,624,683,008 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from pathlib import Path\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "output_data = []\n",
    "words_list = []\n",
    "inputclasses = []\n",
    "documents_vocab = []\n",
    "train_xinput = []\n",
    "train_youtput = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('spawn_en_data.json', encoding='UTF-8') as f:\n",
    "        data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 sentences in training data\n",
      "90 sentences in training data\n"
     ]
    }
   ],
   "source": [
    "output_data = list(data.get('intents'))\n",
    "print(\"%s sentences in training data\" % len(output_data))\n",
    "#print(output_data)\n",
    "print(\"%s sentences in training data\" % len(output_data))\n",
    "\n",
    "ignore_words = ['?']\n",
    "for pattern in output_data:\n",
    "    w = nltk.word_tokenize(pattern['text'])\n",
    "    words_list.extend(w)\n",
    "    documents_vocab.append((w, pattern['intent']))\n",
    "    if pattern['intent'] not in inputclasses:\n",
    "        inputclasses.append(pattern['intent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = LancasterStemmer()\n",
    "words_list = [stemmer.stem(w.lower())\n",
    "                  for w in words_list if w not in ignore_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list = sorted(list(set(words_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'s\",\n",
       " 'a',\n",
       " 'about',\n",
       " 'afternoon',\n",
       " 'am',\n",
       " 'an',\n",
       " 'anyth',\n",
       " 'ar',\n",
       " 'awesom',\n",
       " 'bitch',\n",
       " 'bye',\n",
       " 'bye-by',\n",
       " 'can',\n",
       " 'catch',\n",
       " 'do',\n",
       " 'doing',\n",
       " 'dont',\n",
       " 'dumb',\n",
       " 'fantast',\n",
       " 'fin',\n",
       " 'fuck',\n",
       " 'good',\n",
       " 'goodby',\n",
       " 'gre',\n",
       " 'hav',\n",
       " 'hello',\n",
       " 'help',\n",
       " 'hey',\n",
       " 'hi',\n",
       " 'how',\n",
       " 'i',\n",
       " 'id',\n",
       " 'idiot',\n",
       " 'inspir',\n",
       " 'keep',\n",
       " 'know',\n",
       " 'lastest',\n",
       " 'lat',\n",
       " 'latest',\n",
       " 'lik',\n",
       " 'lov',\n",
       " 'me',\n",
       " 'morn',\n",
       " 'mot',\n",
       " 'motherfuck',\n",
       " 'mou',\n",
       " \"n't\",\n",
       " 'nam',\n",
       " 'nee',\n",
       " 'new',\n",
       " 'no',\n",
       " 'not',\n",
       " 'noth',\n",
       " 'ok',\n",
       " 'profess',\n",
       " 'quiet',\n",
       " 'quot',\n",
       " 'see',\n",
       " 'send',\n",
       " 'show',\n",
       " 'shut',\n",
       " 'skil',\n",
       " 'spawn',\n",
       " 'stupid',\n",
       " 'talk',\n",
       " 'tel',\n",
       " 'thank',\n",
       " 'the',\n",
       " 'ther',\n",
       " 'thing',\n",
       " 'to',\n",
       " 'today',\n",
       " 'up',\n",
       " 'want',\n",
       " 'what',\n",
       " 'who',\n",
       " 'yo',\n",
       " 'you']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputclasses = sorted(list(set(inputclasses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['afernoon',\n",
       " 'bot_bye',\n",
       " 'bot_greet_reply',\n",
       " 'bot_hi',\n",
       " 'bot_identity',\n",
       " 'bot_love',\n",
       " 'bot_negative',\n",
       " 'bot_news',\n",
       " 'bot_quotes',\n",
       " 'bot_shutup',\n",
       " 'bot_skills',\n",
       " 'bot_thanks',\n",
       " 'greet',\n",
       " 'morning',\n",
       " 'spawn_name']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['words'] = words_list\n",
    "data['classes'] = inputclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'words': [\"'s\",\n",
       "  'a',\n",
       "  'about',\n",
       "  'afternoon',\n",
       "  'am',\n",
       "  'an',\n",
       "  'anyth',\n",
       "  'ar',\n",
       "  'awesom',\n",
       "  'bitch',\n",
       "  'bye',\n",
       "  'bye-by',\n",
       "  'can',\n",
       "  'catch',\n",
       "  'do',\n",
       "  'doing',\n",
       "  'dont',\n",
       "  'dumb',\n",
       "  'fantast',\n",
       "  'fin',\n",
       "  'fuck',\n",
       "  'good',\n",
       "  'goodby',\n",
       "  'gre',\n",
       "  'hav',\n",
       "  'hello',\n",
       "  'help',\n",
       "  'hey',\n",
       "  'hi',\n",
       "  'how',\n",
       "  'i',\n",
       "  'id',\n",
       "  'idiot',\n",
       "  'inspir',\n",
       "  'keep',\n",
       "  'know',\n",
       "  'lastest',\n",
       "  'lat',\n",
       "  'latest',\n",
       "  'lik',\n",
       "  'lov',\n",
       "  'me',\n",
       "  'morn',\n",
       "  'mot',\n",
       "  'motherfuck',\n",
       "  'mou',\n",
       "  \"n't\",\n",
       "  'nam',\n",
       "  'nee',\n",
       "  'new',\n",
       "  'no',\n",
       "  'not',\n",
       "  'noth',\n",
       "  'ok',\n",
       "  'profess',\n",
       "  'quiet',\n",
       "  'quot',\n",
       "  'see',\n",
       "  'send',\n",
       "  'show',\n",
       "  'shut',\n",
       "  'skil',\n",
       "  'spawn',\n",
       "  'stupid',\n",
       "  'talk',\n",
       "  'tel',\n",
       "  'thank',\n",
       "  'the',\n",
       "  'ther',\n",
       "  'thing',\n",
       "  'to',\n",
       "  'today',\n",
       "  'up',\n",
       "  'want',\n",
       "  'what',\n",
       "  'who',\n",
       "  'yo',\n",
       "  'you'],\n",
       " 'classes': ['afernoon',\n",
       "  'bot_bye',\n",
       "  'bot_greet_reply',\n",
       "  'bot_hi',\n",
       "  'bot_identity',\n",
       "  'bot_love',\n",
       "  'bot_negative',\n",
       "  'bot_news',\n",
       "  'bot_quotes',\n",
       "  'bot_shutup',\n",
       "  'bot_skills',\n",
       "  'bot_thanks',\n",
       "  'greet',\n",
       "  'morning',\n",
       "  'spawn_name']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json', 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = []\n",
    "output_data = []\n",
    "output_empty = [0] * len(inputclasses)\n",
    "\n",
    "for doc in documents_vocab:\n",
    "    bag = []\n",
    "    pattern_words = doc[0]\n",
    "    pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n",
    "    for w in words_list:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "\n",
    "    output_row = list(output_empty)\n",
    "    output_row[inputclasses.index(doc[1])] = 1\n",
    "\n",
    "    training.append([bag, output_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "train_xinput = list(training[:, 0])\n",
    "train_youtput = list(training[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\amarthak\\python\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From c:\\users\\amarthak\\python\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/95\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 2.6862 - accuracy: 0.0833\n",
      "Epoch 2/95\n",
      "180/180 [==============================] - 0s 127us/step - loss: 2.6274 - accuracy: 0.3222\n",
      "Epoch 3/95\n",
      "180/180 [==============================] - 0s 128us/step - loss: 2.5604 - accuracy: 0.3667\n",
      "Epoch 4/95\n",
      "180/180 [==============================] - 0s 122us/step - loss: 2.4788 - accuracy: 0.3667\n",
      "Epoch 5/95\n",
      "180/180 [==============================] - 0s 122us/step - loss: 2.3829 - accuracy: 0.4333\n",
      "Epoch 6/95\n",
      "180/180 [==============================] - 0s 122us/step - loss: 2.2667 - accuracy: 0.4556\n",
      "Epoch 7/95\n",
      "180/180 [==============================] - 0s 111us/step - loss: 2.1285 - accuracy: 0.4889\n",
      "Epoch 8/95\n",
      "180/180 [==============================] - 0s 127us/step - loss: 1.9775 - accuracy: 0.5000\n",
      "Epoch 9/95\n",
      "180/180 [==============================] - 0s 116us/step - loss: 1.8183 - accuracy: 0.5278\n",
      "Epoch 10/95\n",
      "180/180 [==============================] - 0s 116us/step - loss: 1.6617 - accuracy: 0.5833\n",
      "Epoch 11/95\n",
      "180/180 [==============================] - 0s 111us/step - loss: 1.4997 - accuracy: 0.6556\n",
      "Epoch 12/95\n",
      "180/180 [==============================] - 0s 111us/step - loss: 1.3466 - accuracy: 0.7222\n",
      "Epoch 13/95\n",
      "180/180 [==============================] - 0s 116us/step - loss: 1.2026 - accuracy: 0.7667\n",
      "Epoch 14/95\n",
      "180/180 [==============================] - 0s 116us/step - loss: 1.0597 - accuracy: 0.8444\n",
      "Epoch 15/95\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.9298 - accuracy: 0.8611\n",
      "Epoch 16/95\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.8062 - accuracy: 0.8944\n",
      "Epoch 17/95\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.7005 - accuracy: 0.9111\n",
      "Epoch 18/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.6048 - accuracy: 0.9111\n",
      "Epoch 19/95\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.5268 - accuracy: 0.9167\n",
      "Epoch 20/95\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.4534 - accuracy: 0.9500\n",
      "Epoch 21/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.3960 - accuracy: 0.9611\n",
      "Epoch 22/95\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.3438 - accuracy: 0.9611\n",
      "Epoch 23/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.3006 - accuracy: 0.9778\n",
      "Epoch 24/95\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.2650 - accuracy: 0.9778\n",
      "Epoch 25/95\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.2314 - accuracy: 0.9889\n",
      "Epoch 26/95\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.2048 - accuracy: 0.9889\n",
      "Epoch 27/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.1832 - accuracy: 0.9889\n",
      "Epoch 28/95\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.1628 - accuracy: 0.9889\n",
      "Epoch 29/95\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.1476 - accuracy: 0.9889\n",
      "Epoch 30/95\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.1320 - accuracy: 0.9889\n",
      "Epoch 31/95\n",
      "180/180 [==============================] - 0s 116us/step - loss: 0.1193 - accuracy: 0.9889\n",
      "Epoch 32/95\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.1102 - accuracy: 0.9889\n",
      "Epoch 33/95\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.1055 - accuracy: 0.9889\n",
      "Epoch 34/95\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.0942 - accuracy: 0.9889\n",
      "Epoch 35/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0857 - accuracy: 0.9889\n",
      "Epoch 36/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0805 - accuracy: 0.9889\n",
      "Epoch 37/95\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.0749 - accuracy: 0.9889\n",
      "Epoch 38/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0697 - accuracy: 0.9889\n",
      "Epoch 39/95\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.0653 - accuracy: 0.9889\n",
      "Epoch 40/95\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.0615 - accuracy: 0.9889\n",
      "Epoch 41/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0586 - accuracy: 0.9889\n",
      "Epoch 42/95\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.0557 - accuracy: 0.9889\n",
      "Epoch 43/95\n",
      "180/180 [==============================] - 0s 473us/step - loss: 0.0526 - accuracy: 0.9889\n",
      "Epoch 44/95\n",
      "180/180 [==============================] - 0s 133us/step - loss: 0.0505 - accuracy: 0.9889\n",
      "Epoch 45/95\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.0492 - accuracy: 0.9889\n",
      "Epoch 46/95\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.0462 - accuracy: 0.9889\n",
      "Epoch 47/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0445 - accuracy: 0.9889\n",
      "Epoch 48/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0444 - accuracy: 0.9889\n",
      "Epoch 49/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0418 - accuracy: 0.9889\n",
      "Epoch 50/95\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.0398 - accuracy: 0.9889\n",
      "Epoch 51/95\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.0388 - accuracy: 0.9889\n",
      "Epoch 52/95\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.0376 - accuracy: 0.9889\n",
      "Epoch 53/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0364 - accuracy: 0.9889\n",
      "Epoch 54/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0360 - accuracy: 0.9889\n",
      "Epoch 55/95\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.0346 - accuracy: 0.9889\n",
      "Epoch 56/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0333 - accuracy: 0.9889\n",
      "Epoch 57/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0327 - accuracy: 0.9889\n",
      "Epoch 58/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0328 - accuracy: 0.9889\n",
      "Epoch 59/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0314 - accuracy: 0.9889\n",
      "Epoch 60/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0304 - accuracy: 0.9889\n",
      "Epoch 61/95\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.0302 - accuracy: 0.9889\n",
      "Epoch 62/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0295 - accuracy: 0.9889\n",
      "Epoch 63/95\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.0288 - accuracy: 0.9889\n",
      "Epoch 64/95\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.0296 - accuracy: 0.9889\n",
      "Epoch 65/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0279 - accuracy: 0.9889\n",
      "Epoch 66/95\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.0278 - accuracy: 0.9889\n",
      "Epoch 67/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0290 - accuracy: 0.9778\n",
      "Epoch 68/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0277 - accuracy: 0.9889\n",
      "Epoch 69/95\n",
      "180/180 [==============================] - 0s 105us/step - loss: 0.0269 - accuracy: 0.9889\n",
      "Epoch 70/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0255 - accuracy: 0.9889\n",
      "Epoch 71/95\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.0257 - accuracy: 0.9889\n",
      "Epoch 72/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0250 - accuracy: 0.9889\n",
      "Epoch 73/95\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.0255 - accuracy: 0.9889\n",
      "Epoch 74/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0255 - accuracy: 0.9889\n",
      "Epoch 75/95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 94us/step - loss: 0.0240 - accuracy: 0.9889\n",
      "Epoch 76/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0245 - accuracy: 0.9889\n",
      "Epoch 77/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0237 - accuracy: 0.9889\n",
      "Epoch 78/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0241 - accuracy: 0.9778\n",
      "Epoch 79/95\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.0233 - accuracy: 0.9889\n",
      "Epoch 80/95\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.0237 - accuracy: 0.9889\n",
      "Epoch 81/95\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.0235 - accuracy: 0.9778\n",
      "Epoch 82/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0225 - accuracy: 0.9889\n",
      "Epoch 83/95\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.0238 - accuracy: 0.9778\n",
      "Epoch 84/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0239 - accuracy: 0.9889\n",
      "Epoch 85/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0229 - accuracy: 0.9833\n",
      "Epoch 86/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0224 - accuracy: 0.9778\n",
      "Epoch 87/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0241 - accuracy: 0.9778\n",
      "Epoch 88/95\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.0219 - accuracy: 0.9833\n",
      "Epoch 89/95\n",
      "180/180 [==============================] - 0s 111us/step - loss: 0.0211 - accuracy: 0.9833\n",
      "Epoch 90/95\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.0213 - accuracy: 0.9889\n",
      "Epoch 91/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0215 - accuracy: 0.9889\n",
      "Epoch 92/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0209 - accuracy: 0.9889\n",
      "Epoch 93/95\n",
      "180/180 [==============================] - 0s 94us/step - loss: 0.0213 - accuracy: 0.9889\n",
      "Epoch 94/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0219 - accuracy: 0.9778\n",
      "Epoch 95/95\n",
      "180/180 [==============================] - 0s 100us/step - loss: 0.0208 - accuracy: 0.9889\n"
     ]
    }
   ],
   "source": [
    "model_nn = Sequential()\n",
    "model_nn.add(Dense(32, input_dim=len(train_xinput[0]), activation='relu'))\n",
    "model_nn.add(Dense(16, activation='relu'))\n",
    "model_nn.add(Dense(len(train_youtput[0]), activation='softmax'))\n",
    "\n",
    "model_nn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_nn.fit(np.array(train_xinput), np.array(train_youtput), epochs=95, batch_size=8)\n",
    "\n",
    "model_nn.save('spawn_en.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tflite_convert --keras_model_file=spawn_en.h5 --output_file=spawn_en.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}